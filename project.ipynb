{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PEP8 compliant code checker\n",
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import os\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# CONSTANTS\n",
    "VIDEO_PATH = \"acquisizione1.mp4\"  # Path to the video\n",
    "\n",
    "\n",
    "# FUNCTIONS\n",
    "\n",
    "def file_exist(path):\n",
    "    if not os.path.exists(path):\n",
    "        print(\"File does not exist.\")\n",
    "        return\n",
    "    if not os.path.isfile(path):\n",
    "        print(\"Path does not lead to the file.\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tresholds' meaning is explained here :) https://docs.opencv.org/4.x/da/d22/tutorial_py_canny.html\n",
    "I've tried some possible values and these two looked as a fine compromise. Maybe we can push a little more the treshold to have less noisy images. \n",
    "**Note: if the programme doesn't find a video, it does not crash. It simply does nothing. Be aware of this**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "frameCount = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "frameCount = 1000  # Override\n",
    "frameWidth = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "frameHeight = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "video = np.empty((frameCount, frameHeight, frameWidth), np.dtype('uint8'))\n",
    "\n",
    "for i in range(frameCount):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    video[i] = frame\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5\n",
    "min_frame = 800\n",
    "max_frame = 802\n",
    "window_size = 10\n",
    "\n",
    "\n",
    "processframeCount = max_frame - min_frame\n",
    "size = (processframeCount, frameHeight, frameWidth)\n",
    "\n",
    "video_window = np.copy(video[min_frame:max_frame])\n",
    "video_nobg = np.copy(video_window)\n",
    "video_deviation = np.empty(size, dtype=np.float16)\n",
    "video_average = np.empty(size, dtype=np.float16)\n",
    "for i in range(0, processframeCount):\n",
    "    n = i + min_frame\n",
    "    m = i + window_size + min_frame\n",
    "    video_smooth = gaussian_filter(video[n:m], sigma=1.0)\n",
    "    video_deviation[i] = np.std(video_smooth, axis=0)\n",
    "\n",
    "# video_deviation[] = \n",
    "threshold2 = 10\n",
    "video_nobg[video_deviation < threshold] = 0\n",
    "video_nobg[video_deviation > threshold2] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_idx = 0\n",
    "\n",
    "edged = cv.Canny(video_nobg[image_idx], 10, 100) \n",
    "contours, hierarchy = cv.findContours(edged, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n",
    "\n",
    "scale = 50\n",
    "\n",
    "\n",
    "plt.figure(figsize=(frameHeight // scale, frameWidth // scale))\n",
    "plt.imshow(video_window[image_idx], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# video_nobg_hh = cv.adaptiveThreshold(video_nobg[image_idx], 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY_INV, 11, 5)\n",
    "\n",
    "# plt.figure(figsize=(frameHeight // scale, frameWidth // scale))\n",
    "# plt.imshow(video_nobg_hh, cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "plt.figure(figsize=(frameHeight // scale, frameWidth // scale))\n",
    "plt.imshow(video_nobg[image_idx], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(frameHeight // scale, frameWidth // scale))\n",
    "plt.imshow(edged, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countour_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(contours))\n",
    "contours_area = tuple(map(cv.contourArea, contours))\n",
    "max_idx = contours_area.index(max(contours_area))\n",
    "print(max_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_idx = 71  # -1 means all countours are drawn\n",
    "\n",
    "blank_image = np.ones((frameHeight, frameWidth), np.dtype('uint8')) * 200\n",
    "cv.drawContours(blank_image, contours, contour_idx, 255, 2) \n",
    "\n",
    "plt.figure(figsize=(frameHeight // scale, frameWidth // scale))\n",
    "plt.imshow(blank_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.contourArea(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(frameCount):\n",
    "    cv.imshow(\"After filtering\", video_nobg[i])\n",
    "    cv.imshow(\"Before filtering\", video_window[i])\n",
    "    if cv.waitKey(100) == ord('q'):\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_exist(video_path)\n",
    "\n",
    "\n",
    "cap = cv.VideoCapture(video_path)\n",
    "fast = cv.FastFeatureDetector_create(threshold = 100)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    #gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    cv.imshow('frame', frame)\n",
    "\n",
    "# find and draw the keypoints\n",
    "    img= cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\n",
    "    kp = fast.detect(frame,None)\n",
    "    \n",
    "    img2 = cv.drawKeypoints(img, kp, None, color=(255,0,0))\n",
    "    cv.imshow('Fast detector', img2)\n",
    "    if cv.waitKey(0.1) == ord('q'): #this letter q is the character needed to stop showing the video. \n",
    "        break\n",
    "    #print( \"Threshold: {}\".format(fast.getThreshold()) )\n",
    "#print( \"nonmaxSuppression:{}\".format(fast.getNonmaxSuppression()) )\n",
    "#print( \"neighborhood: {}\".format(fast.getType()) )\n",
    "#print( \"Total Keypoints with nonmaxSuppression: {}\".format(len(kp)) )\n",
    "\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "video.isOpened()\n",
    "    sift = cv.SIFT_create(contrastThreshold = 0.1)\n",
    "    kp = sift.detect(gray,None)\n",
    "    sifted = cv.drawKeypoints(gray, kp,frame)\n",
    "    cv.imshow(\"sift\", sifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cv.findContours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This video is very intresting. But it gives me an error I don't know how to fix. I'll look in it later.\n",
    "https://www.youtube.com/watch?v=YrxhUePkAiY\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function will do the following: \n",
    "$(1- \\alpha)\\cdot destination(x,y)+ \\alpha \\cdot source(x,y)$\n",
    "only if $mask(x,y) \\neq 0$\n",
    "This last one is the one I've tested more. As you can see I already append to a list (frames_deltas) all the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv.VideoCapture(VIDEO_PATH)\n",
    "ret, frame = vid.read()\n",
    "avarage1 = np.float32(frame)\n",
    "frames_deltas = []\n",
    "#print(len(frame), len(frame[0]), len(frame[0][0]))\n",
    "#print(frame[0][0])\n",
    "while (vid.isOpened()) :\n",
    "\n",
    "    ret, frame = vid.read()\n",
    "    if  ret:\n",
    "        \n",
    "        \n",
    "        cv.accumulateWeighted( frame, avarage1, 0.005)\n",
    "        \n",
    "        frameDelta = cv.absdiff(frame, cv.convertScaleAbs(avarage1))\n",
    "        frames_deltas.append(frameDelta)\n",
    "        cv.imshow(\"Original\", cv.resize(frame,(825,550))) #resize function changes size of the window that displays the image\n",
    "        cv.imshow(\"Only changes\", cv.resize(frameDelta,(825,550)))\n",
    "        \n",
    "        #    break\n",
    "        if cv.waitKey(frametime) == ord('q'): #this letter q is the character needed to stop showing the video. \n",
    "            break\n",
    "    else:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        vid.release()\n",
    "        cv.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv.VideoCapture(VIDEO_PATH)\n",
    "ret, frame = vid.read()\n",
    "avarage1 = np.float32(frame)\n",
    "frames_deltas = []\n",
    "frametime = 10\n",
    "#print(len(frame), len(frame[0]), len(frame[0][0]))\n",
    "#print(frame[0][0])\n",
    "while vid.isOpened():\n",
    "\n",
    "    ret, frame = vid.read()\n",
    "    if  ret:\n",
    "        \n",
    "        \n",
    "        cv.accumulateWeighted( frame, avarage1, 0.005)\n",
    "        \n",
    "        frameDelta = cv.absdiff(frame, cv.convertScaleAbs(avarage1))\n",
    "        frames_deltas.append(frameDelta)\n",
    "        cv.imshow(\"Original\", cv.resize(frame,(825,550))) #resize function changes size of the window that displays the image\n",
    "        cv.imshow(\"Only changes\", cv.resize(frameDelta,(825,550)))\n",
    "        \n",
    "        #    break\n",
    "        if cv.waitKey(frametime) == ord('q'): #this letter q is the character needed to stop showing the video. \n",
    "            break\n",
    "    else:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        vid.release()\n",
    "        cv.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kill_video(vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dd(h):\n",
    "    global global_variable\n",
    "    if var_name in globals():\n",
    "        del globals()[var_name]\n",
    "        del globals()[var_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
